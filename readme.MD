# LLaMa V2 7B serving (with Flask)

Serve the LLaMa V2 7B model on a local machine using Flask. 

Please refer below link

## [LLaMa V2 서빙하기 (with Flask)](https://kim-yh.notion.site/LLM-with-Flask-7397732913cf4845a4c286daa92b2427)

